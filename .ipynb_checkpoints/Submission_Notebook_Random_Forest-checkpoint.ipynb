{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import io\n",
    "import random as r\n",
    "\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "# For downsampling\n",
    "from sklearn.utils import resample,shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_companies = pd.read_csv(\"./data/companies.csv\")\n",
    "df_payments = pd.read_csv(\"./data/payments.csv\")\n",
    "df_physicians = pd.read_csv(\"./data/physicians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>set</th>\n",
       "      <th>First_Name</th>\n",
       "      <th>Middle_Name</th>\n",
       "      <th>Last_Name</th>\n",
       "      <th>Name_Suffix</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Zipcode</th>\n",
       "      <th>Country</th>\n",
       "      <th>Province</th>\n",
       "      <th>Primary_Specialty</th>\n",
       "      <th>License_State_1</th>\n",
       "      <th>License_State_2</th>\n",
       "      <th>License_State_3</th>\n",
       "      <th>License_State_4</th>\n",
       "      <th>License_State_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>LEIGH</td>\n",
       "      <td>B</td>\n",
       "      <td>HOPPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FORT PIERCE</td>\n",
       "      <td>FL</td>\n",
       "      <td>34950</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Obstetrics...</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>STEVEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRANK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TOWSON</td>\n",
       "      <td>MD</td>\n",
       "      <td>21204-6808</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Anesthesio...</td>\n",
       "      <td>MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "      <td>THOMAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COUCH</td>\n",
       "      <td>JR.</td>\n",
       "      <td>TROY</td>\n",
       "      <td>NY</td>\n",
       "      <td>12180-2832</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Podiatric Medicine &amp; Surgery Service Providers...</td>\n",
       "      <td>NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>train</td>\n",
       "      <td>CLAUDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAVANNAH</td>\n",
       "      <td>GA</td>\n",
       "      <td>31419-1753</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Internal M...</td>\n",
       "      <td>GA</td>\n",
       "      <td>SC</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>C</td>\n",
       "      <td>SCHENCK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALBUQUERQUE</td>\n",
       "      <td>NM</td>\n",
       "      <td>87131-0001</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Orthopaedi...</td>\n",
       "      <td>NM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5996</td>\n",
       "      <td>train</td>\n",
       "      <td>MARC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WEINSTEIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEMPLE TERRACE</td>\n",
       "      <td>FL</td>\n",
       "      <td>33637-0925</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Orthopaedi...</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>5997</td>\n",
       "      <td>train</td>\n",
       "      <td>CHARLES</td>\n",
       "      <td>W</td>\n",
       "      <td>YOWELL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TALLAHASSEE</td>\n",
       "      <td>FL</td>\n",
       "      <td>32308-4620</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Urology</td>\n",
       "      <td>FL</td>\n",
       "      <td>SC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>5998</td>\n",
       "      <td>train</td>\n",
       "      <td>MARK</td>\n",
       "      <td>O</td>\n",
       "      <td>GABBIE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEXARKANA</td>\n",
       "      <td>AR</td>\n",
       "      <td>71854</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Family Med...</td>\n",
       "      <td>AR</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>5999</td>\n",
       "      <td>test</td>\n",
       "      <td>KRISHNASWAMY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAJARAJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RANDOLPH</td>\n",
       "      <td>MA</td>\n",
       "      <td>02368-2100</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Psychiatry...</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>6000</td>\n",
       "      <td>train</td>\n",
       "      <td>HOWARD</td>\n",
       "      <td>K</td>\n",
       "      <td>NAM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YUBA CITY</td>\n",
       "      <td>CA</td>\n",
       "      <td>95991-5005</td>\n",
       "      <td>UNITED STATES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Allopathic &amp; Osteopathic Physicians|Otolaryngo...</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id    set    First_Name Middle_Name  Last_Name Name_Suffix  \\\n",
       "0        1  train         LEIGH           B      HOPPE         NaN   \n",
       "1        2  train        STEVEN         NaN      FRANK         NaN   \n",
       "2        3  train        THOMAS         NaN      COUCH         JR.   \n",
       "3        4  train        CLAUDE         NaN         SU         NaN   \n",
       "4        5  train        ROBERT           C    SCHENCK         NaN   \n",
       "...    ...    ...           ...         ...        ...         ...   \n",
       "5995  5996  train          MARC         NaN  WEINSTEIN         NaN   \n",
       "5996  5997  train       CHARLES           W     YOWELL         NaN   \n",
       "5997  5998  train          MARK           O     GABBIE         NaN   \n",
       "5998  5999   test  KRISHNASWAMY         NaN    GAJARAJ         NaN   \n",
       "5999  6000  train        HOWARD           K        NAM         NaN   \n",
       "\n",
       "                City State     Zipcode        Country  Province  \\\n",
       "0        FORT PIERCE    FL       34950  UNITED STATES       NaN   \n",
       "1             TOWSON    MD  21204-6808  UNITED STATES       NaN   \n",
       "2               TROY    NY  12180-2832  UNITED STATES       NaN   \n",
       "3           SAVANNAH    GA  31419-1753  UNITED STATES       NaN   \n",
       "4        ALBUQUERQUE    NM  87131-0001  UNITED STATES       NaN   \n",
       "...              ...   ...         ...            ...       ...   \n",
       "5995  TEMPLE TERRACE    FL  33637-0925  UNITED STATES       NaN   \n",
       "5996     TALLAHASSEE    FL  32308-4620  UNITED STATES       NaN   \n",
       "5997       TEXARKANA    AR       71854  UNITED STATES       NaN   \n",
       "5998        RANDOLPH    MA  02368-2100  UNITED STATES       NaN   \n",
       "5999       YUBA CITY    CA  95991-5005  UNITED STATES       NaN   \n",
       "\n",
       "                                      Primary_Specialty License_State_1  \\\n",
       "0     Allopathic & Osteopathic Physicians|Obstetrics...              FL   \n",
       "1     Allopathic & Osteopathic Physicians|Anesthesio...              MD   \n",
       "2     Podiatric Medicine & Surgery Service Providers...              NY   \n",
       "3     Allopathic & Osteopathic Physicians|Internal M...              GA   \n",
       "4     Allopathic & Osteopathic Physicians|Orthopaedi...              NM   \n",
       "...                                                 ...             ...   \n",
       "5995  Allopathic & Osteopathic Physicians|Orthopaedi...              FL   \n",
       "5996        Allopathic & Osteopathic Physicians|Urology              FL   \n",
       "5997  Allopathic & Osteopathic Physicians|Family Med...              AR   \n",
       "5998  Allopathic & Osteopathic Physicians|Psychiatry...              MA   \n",
       "5999  Allopathic & Osteopathic Physicians|Otolaryngo...              CA   \n",
       "\n",
       "     License_State_2 License_State_3 License_State_4 License_State_5  \n",
       "0                NaN             NaN             NaN             NaN  \n",
       "1                NaN             NaN             NaN             NaN  \n",
       "2                NaN             NaN             NaN             NaN  \n",
       "3                 SC              AL             NaN             NaN  \n",
       "4                NaN             NaN             NaN             NaN  \n",
       "...              ...             ...             ...             ...  \n",
       "5995             NaN             NaN             NaN             NaN  \n",
       "5996              SC             NaN             NaN             NaN  \n",
       "5997              TX             NaN             NaN             NaN  \n",
       "5998             NaN             NaN             NaN             NaN  \n",
       "5999             NaN             NaN             NaN             NaN  \n",
       "\n",
       "[6000 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df_physicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phys_OI(phys_id):\n",
    "    if(df_payments.query('Physician_ID==@phys_id and Ownership_Indicator==\"Yes\"').shape[0]>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_physicians['Ownership_Interest']=df_physicians['id'].apply(phys_OI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_physicians.query('Ownership_Interest==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.rename({\"State\":\"State_Comp\",\"Country\":\"Country_Comp\"}, axis='columns', inplace=True)\n",
    "df_physicians.rename({\"State\":\"State_Phys\",\"Country\":\"Country_Phys\"}, axis='columns', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.merge(df_payments, df_physicians, left_on='Physician_ID', right_on='id', how='left').drop('id', axis=1)\n",
    "df = pd.merge(df, df_companies, on='Company_ID', how='left')\n",
    "df.rename({\"Name\":\"Company_Name\"}, axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "###test safekeeping dataframe\n",
    "df_main_test=df[df.set==\"test\"]\n",
    "\n",
    "df = df.astype(str)\n",
    "for column in df.columns:\n",
    "     if(df[column].dtype=='object'):\n",
    "        df[column] = df[column].str.lower()\n",
    "\n",
    "#Convert to Date\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "#type conv after str conv\n",
    "df[['Company_ID','Number_of_Payments']]=df[['Company_ID','Number_of_Payments']].astype(int)\n",
    "df['Total_Amount_of_Payment_USDollars']=df['Total_Amount_of_Payment_USDollars'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DROPPING RECORDS\n",
    "df_scrap=df.query('Product_Code_1!=\"nan\" and Product_Name_1==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n",
    "\n",
    "df_scrap=df.query('Product_Code_2!=\"nan\" and Product_Name_2==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n",
    "\n",
    "df_scrap=df.query('Product_Code_3!=\"nan\" and Product_Name_3==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENCODING CELL\n",
    "\n",
    "name_list = pd.unique(df[['Product_Name_1', 'Product_Name_2', 'Product_Name_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Name_1'] = df['Product_Name_1'].apply(product_encode)\n",
    "df['Product_Name_2'] = df['Product_Name_2'].apply(product_encode)\n",
    "df['Product_Name_3'] = df['Product_Name_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Code_1', 'Product_Code_2', 'Product_Code_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Code_1'] = df['Product_Code_1'].apply(product_encode)\n",
    "df['Product_Code_2'] = df['Product_Code_2'].apply(product_encode)\n",
    "df['Product_Code_3'] = df['Product_Code_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Category_1', 'Product_Category_2', 'Product_Category_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Category_1'] = df['Product_Category_1'].apply(product_encode)\n",
    "df['Product_Category_2'] = df['Product_Category_2'].apply(product_encode)\n",
    "df['Product_Category_3'] = df['Product_Category_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Type_1', 'Product_Type_2','Product_Type_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Type_1'] = df['Product_Type_1'].apply(product_encode)\n",
    "df['Product_Type_2'] = df['Product_Type_2'].apply(product_encode)\n",
    "df['Product_Type_3'] = df['Product_Type_3'].apply(product_encode)\n",
    "\n",
    "\n",
    "name_list = pd.unique(df[['License_State_1', 'License_State_2', 'License_State_3', 'License_State_4', 'License_State_5']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def license_encode(license_state):\n",
    "    return name_list_dict.get(license_state)\n",
    "\n",
    "df['License_State_1']=df['License_State_1'].apply(license_encode)\n",
    "df['License_State_2']=df['License_State_2'].apply(license_encode)\n",
    "df['License_State_3']=df['License_State_3'].apply(license_encode)\n",
    "df['License_State_4']=df['License_State_4'].apply(license_encode)\n",
    "df['License_State_5']=df['License_State_5'].apply(license_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Country_Comp', 'Country_Phys','Country_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Country_Comp'] = df['Country_Comp'].apply(product_encode)\n",
    "df['Country_Phys'] = df['Country_Phys'].apply(product_encode)\n",
    "df['Country_of_Travel'] = df['Country_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['State_Comp', 'State_Phys', 'State_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['State_Comp'] = df['State_Comp'].apply(product_encode)\n",
    "df['State_Phys'] = df['State_Phys'].apply(product_encode)\n",
    "df['State_of_Travel'] = df['State_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['City_of_Travel', 'City']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['City_of_Travel'] = df['City_of_Travel'].apply(product_encode)\n",
    "df['City'] = df['City'].apply(product_encode)\n",
    "\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"yes\"),1,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"no\"),0,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=df['Ownership_Indicator'].astype(int)\n",
    "\n",
    "df['Date_year']=df['Date'].dt.year\n",
    "df['Date_month']=df['Date'].dt.month\n",
    "df['Date_day']=df['Date'].dt.day\n",
    "\n",
    "columns_encode=['Nature_of_Payment_or_Transfer_of_Value','Form_of_Payment_or_Transfer_of_Value','Zipcode','Third_Party_Recipient', 'Charity', 'Third_Party_Covered','Contextual_Information', 'Related_Product_Indicator','Primary_Specialty']\n",
    "for column in columns_encode:\n",
    "    df[column]=df[column].astype('category')\n",
    "    df[column]=df[column].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DROPPING COLUMNS\n",
    "df_safe = df\n",
    "df.drop(columns=['Date','Record_ID', 'First_Name', 'Middle_Name', 'Last_Name', 'Name_Suffix', 'Company_Name','Province'],inplace=True)\n",
    "# df.drop(columns=['Date','Record_ID', 'First_Name', 'Middle_Name', 'Last_Name', 'Name_Suffix', 'Company_Name','Province','Product_Type_1','Product_Type_2','Product_Type_3','Product_Code_1','Product_Code_2','Product_Code_3'],inplace=True)\n",
    "\n",
    "###SPLIT\n",
    "df_test=df[df.set==\"test\"]\n",
    "df_train=df[df.set==\"train\"]\n",
    "\n",
    "###drop set column\n",
    "df_test.drop(columns=['set'],inplace=True)\n",
    "df_train.drop(columns=['set'],inplace=True)\n",
    "\n",
    "##send predicted attribute to end\n",
    "first_col = df_train.pop(\"Ownership_Interest\")\n",
    "df_train.insert((df_train.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Ownership_Interest\")\n",
    "df_test.insert((df_test.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "##send Physician ID to end\n",
    "first_col = df_train.pop(\"Physician_ID\")\n",
    "df_train.insert((df_train.shape[1]),\"Physician_ID\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Physician_ID\")\n",
    "df_test.insert((df_test.shape[1]),\"Physician_ID\",first_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##heatmap cell\n",
    "fig = plt.figure(figsize = (30,30))\n",
    "ax = fig.gca()\n",
    "\n",
    "heatmap = sns.heatmap(df_train[df_train.columns[0:41]].corr(), annot=True)\n",
    "fig = heatmap.get_figure()\n",
    "fig.savefig(\"heatmap_after_na_encode_OI.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best=0\n",
    "i=0\n",
    "n=5\n",
    "f = open(\"seeds.txt\", \"a\")\n",
    "f.write(\"File Starts here:\\n\")\n",
    "\n",
    "while n>0:\n",
    "    i+=1\n",
    "    r_seed1=r.randint(0, 3000)\n",
    "    r_seed2=r.randint(0, 3000)\n",
    "    r_seed3=r.randint(0, 3000)\n",
    "    r_seed4=r.randint(0, 3000)\n",
    "    r_seed5=r.randint(0, 3000)\n",
    "    n_est=r.randint(50,200)\n",
    "    np.random.seed(r_seed1)\n",
    "    ###downsampling\n",
    "    df_train_maj=df_train[df_train.Ownership_Indicator==0]\n",
    "    df_train_min=df_train[df_train.Ownership_Indicator==1]\n",
    "    df_train_maj_down=resample(df_train_maj, replace=False, n_samples=df_train_min.shape[0], random_state=r_seed2)\n",
    "    df_train_final = pd.concat([df_train_maj_down, df_train_min])\n",
    "\n",
    "    ###test train split of own train set\n",
    "    df_train_final['is_train']=np.random.uniform(0,1,len(df_train_final)) <=.80\n",
    "    train, test = df_train_final[df_train_final['is_train']==True], df_train_final[df_train_final['is_train']==False]\n",
    "    train = shuffle(train,random_state=r_seed3)\n",
    "    test = shuffle(test,random_state=r_seed4)\n",
    "\n",
    "    ###feature and label split\n",
    "    features=train[train.columns[0:(train.shape[1]-3)]]\n",
    "    y=train['Ownership_Indicator']\n",
    "    x_test = test[test.columns[0:(test.shape[1]-3)]]\n",
    "    y_test = test['Ownership_Indicator']\n",
    "\n",
    "    ###model training\n",
    "    clf = RandomForestClassifier(n_jobs=-1, oob_score = True, n_estimators = n_est, random_state=r_seed5)\n",
    "\n",
    "    clf.fit(features, y)\n",
    "    test_acc=clf.score(x_test,y_test)\n",
    "#     print('Seed:'+str(r_seed1)+' '+str(r_seed2)+' '+str(r_seed3)+' '+str(r_seed4)+' '+str(r_seed5)+' '+str(test_acc))\n",
    "    \n",
    "    # Accuracy Scores\n",
    "#     print ('Internal Accuracy Score', clf.oob_score_)\n",
    "#     print ('RF accuracy: TRAINING', clf.score(features,y))\n",
    "#     print ('RF accuracy: TESTING', test_acc)\n",
    "    if test_acc>best:\n",
    "        best=test_acc\n",
    "        f.write('BEST:'+str(i)+' '+str(r_seed1)+' '+str(r_seed2)+' '+str(r_seed3)+' '+str(r_seed4)+' '+str(r_seed5)+' '+str(test_acc)+' N_EST: '+str(n_est)+'\\n')\n",
    "        print('BEST:'+str(i)+' '+str(r_seed1)+' '+str(r_seed2)+' '+str(r_seed3)+' '+str(r_seed4)+' '+str(r_seed5)+' '+str(test_acc)+' N_EST: '+str(n_est))\n",
    "    score_test=clf.predict(x_test)\n",
    "    if test_acc>0.9968814968814969:\n",
    "        f.close()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1261 533 2608 1581 2218 641 0.9968814968814969 N_EST: 63\n",
    "r_seed1, r_seed2, r_seed3, r_seed4, r_seed5, n_est= 473, 907, 1680, 322, 318, 142\n",
    "np.random.seed(r_seed1)\n",
    "###downsampling\n",
    "df_train_maj=df_train[df_train.Ownership_Indicator==0]\n",
    "df_train_min=df_train[df_train.Ownership_Indicator==1]\n",
    "df_train_maj_down=resample(df_train_maj, replace=False, n_samples=df_train_min.shape[0], random_state=r_seed2)\n",
    "df_train_final = pd.concat([df_train_maj_down, df_train_min])\n",
    "\n",
    "###test train split of own train set\n",
    "df_train_final['is_train']=np.random.uniform(0,1,len(df_train_final)) <=.80\n",
    "train, test = df_train_final[df_train_final['is_train']==True], df_train_final[df_train_final['is_train']==False]\n",
    "train = shuffle(train,random_state=r_seed3)\n",
    "test = shuffle(test,random_state=r_seed4)\n",
    "\n",
    "###feature and label split\n",
    "features=train[train.columns[0:(train.shape[1]-3)]]\n",
    "y=train['Ownership_Indicator']\n",
    "x_test = test[test.columns[0:(test.shape[1]-3)]]\n",
    "y_test = test['Ownership_Indicator']\n",
    "\n",
    "###model training\n",
    "clf = RandomForestClassifier(n_jobs=-1, oob_score = True, n_estimators = n_est, random_state=r_seed5)\n",
    "clf.fit(features, y)\n",
    "test_acc=clf.score(x_test,y_test)\n",
    "\n",
    "    # Accuracy Scores\n",
    "print ('Internal Accuracy Score', clf.oob_score_)\n",
    "print ('RF accuracy: TRAINING', clf.score(features,y))\n",
    "print ('RF accuracy: TESTING', test_acc)\n",
    "score_test=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Creating Dataframes to find accuracy of Physician Level\n",
    "\n",
    "finalAccPhysID=test['Physician_ID']\n",
    "finalAcc={'Physician_ID':finalAccPhysID, 'Score':score_test}\n",
    "finalAccDF=pd.DataFrame(data=finalAcc)\n",
    "# finalAccDF['Physician_ID'].unique().size\n",
    "physUFAD=finalAccDF['Physician_ID'].unique()\n",
    "sc=[None]*physUFAD.size\n",
    "for i in range(physUFAD.size):\n",
    "    physician=physUFAD[i]\n",
    "    if(finalAccDF.query('Physician_ID==@physician and Score==1').shape[0]>0):\n",
    "        sc[i]=1\n",
    "    else:\n",
    "        sc[i]=0\n",
    "        \n",
    "finTestPredict={'Physician_ID':physUFAD, 'Score':sc}\n",
    "finTestPredictDF=pd.DataFrame(data=finTestPredict)\n",
    "\n",
    "TrueFinalAcc={'Physician_ID':finalAccPhysID, 'Score':test['Ownership_Indicator']}\n",
    "TrueFinalAccDF=pd.DataFrame(data=TrueFinalAcc)\n",
    "# finalAccDF['Physician_ID'].unique().size\n",
    "physUFAD=TrueFinalAccDF['Physician_ID'].unique()\n",
    "sc=[None]*physUFAD.size\n",
    "for i in range(physUFAD.size):\n",
    "    physician=physUFAD[i]\n",
    "    if(TrueFinalAccDF.query('Physician_ID==@physician and Score==1').shape[0]>0):\n",
    "        sc[i]=1\n",
    "    else:\n",
    "        sc[i]=0\n",
    "\n",
    "TrueFinTest={'Physician_ID':physUFAD, 'Score':sc}\n",
    "TrueFinTestDF=pd.DataFrame(data=TrueFinTest)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Finding Accuracy\n",
    "ownTestScore=TrueFinTestDF['Score']-finTestPredictDF['Score']\n",
    "print(ownTestScore)\n",
    "accuracy=(ownTestScore.value_counts(dropna=False,sort=False,ascending=True).loc[0])/ownTestScore.size*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test\n",
    "df_test.Physician_ID.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.columns)\n",
    "print(df_test.columns)\n",
    "predict_set=df_test\n",
    "predict_set.drop(columns=['Ownership_Indicator','Physician_ID'],inplace=True)\n",
    "print(features.shape)\n",
    "print(predict_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict(predict_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_id_list=df_main_test['Physician_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit={'Physician_ID':phys_id_list, 'Score':score}\n",
    "submit_df=pd.DataFrame(data=submit)\n",
    "submit_df['Physician_ID'].unique().size\n",
    "physUnique=submit_df['Physician_ID'].unique()\n",
    "physUnique.size\n",
    "physUnique[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc=[None]*1000\n",
    "for i in range(physUnique.size):\n",
    "    physician=physUnique[i]\n",
    "    if(submit_df.query('Physician_ID==@physician and Score==1').shape[0]>0):\n",
    "        sc[i]=1\n",
    "    else:\n",
    "        sc[i]=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit={'id':physUnique, 'prediction':sc}\n",
    "fs_df=pd.DataFrame(data=final_submit)\n",
    "fs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df.to_csv(\"./submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(physUnique)\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect1 = pd.read_csv(\"./submission2.csv\")\n",
    "inspect2 = pd.read_csv(\"./submission3.csv\")\n",
    "dfscrap=inspect2['prediction']-inspect1['prediction']\n",
    "dfscrap.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
