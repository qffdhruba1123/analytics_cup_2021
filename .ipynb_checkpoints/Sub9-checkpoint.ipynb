{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook, trange, tqdm\n",
    "from PIL import Image, ImageDraw\n",
    "import io\n",
    "import random as r\n",
    "\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "# For downsampling\n",
    "from sklearn.utils import resample,shuffle\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"./companies.csv\")\n",
    "df_payments = pd.read_csv(\"./payments.csv\")\n",
    "df_physicians = pd.read_csv(\"./physicians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.rename({\"State\":\"State_Comp\",\"Country\":\"Country_Comp\"}, axis='columns', inplace=True)\n",
    "df_physicians.rename({\"State\":\"State_Phys\",\"Country\":\"Country_Phys\"}, axis='columns', inplace=True)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ownInterest(id):\n",
    "    if(df_payments.query('Physician_ID==@id and Ownership_Indicator==\"Yes\"').shape[0]>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_physicians['Ownership_Interest']=df_physicians['id'].apply(ownInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Ownership Indicators=yes records\n",
    "df_scrap=df_payments.query('Ownership_Indicator==\"Yes\"', engine='python')\n",
    "df_payments=pd.concat([df_payments, df_scrap]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Engineering\n",
    "def total_pay(phys_id):\n",
    "    return df_payments.query('Physician_ID==@phys_id').Total_Amount_of_Payment_USDollars.sum()\n",
    "\n",
    "df_physicians['Total_Payments']=df_physicians['id'].apply(total_pay)\n",
    "\n",
    "def sum_num_pay(phys_id):\n",
    "    return df_payments.query('Physician_ID==@phys_id').Number_of_Payments.sum()\n",
    "\n",
    "df_physicians['Total_Num_Payments']=df_physicians['id'].apply(sum_num_pay)\n",
    "\n",
    "df_physicians['Value_by_Num']=df_physicians['Total_Payments']/df_physicians['Total_Num_Payments']\n",
    "\n",
    "def num_tran(phys_id):\n",
    "    return df_payments.query('Physician_ID==@phys_id').shape[0]\n",
    "\n",
    "df_physicians['Number_Transaction']=df_physicians['id'].apply(num_tran)\n",
    "\n",
    "df_physicians['Value_by_Tran']=df_physicians['Total_Payments']/df_physicians['Number_Transaction']\n",
    "\n",
    "def max_comp(phys_id):\n",
    "    return df_payments.query('Physician_ID==@phys_id').Company_ID.value_counts().index[0]\n",
    "\n",
    "df_physicians['Max_Comp_ID']=df_physicians['id'].apply(max_comp)\n",
    "\n",
    "df_scrap=df_payments\n",
    "\n",
    "def max_comp_value(phys_id):\n",
    "    return df_payments.query('Physician_ID==@phys_id').sort_values('Total_Amount_of_Payment_USDollars',ascending=False).Company_ID.iloc[0]\n",
    "\n",
    "df_physicians['Max_Comp_ID_value']=df_physicians['id'].apply(max_comp_value)\n",
    "\n",
    "# squeeze for product name\n",
    "\n",
    "\n",
    "\n",
    "df_scrap['index_col'] = df_scrap.index\n",
    "df_scrap=pd.wide_to_long(df_scrap, stubnames='Product_Name_', i=['index_col'],j='Product_Name_Number').reset_index()\n",
    "df_scrap.drop(columns=['index_col'],inplace=True)\n",
    "\n",
    "def max_prod_occuring(phys_id):\n",
    "    if(str(df_scrap.query('Physician_ID==@phys_id').Product_Name_.value_counts(dropna=False).index[0])==\"nan\"):\n",
    "        if(df_scrap.query('Physician_ID==@phys_id').Product_Name_.value_counts(dropna=False).size<2):\n",
    "            return df_scrap.query('Physician_ID==@phys_id').Product_Name_.value_counts(dropna=False).index[0]\n",
    "        else:\n",
    "            return df_scrap.query('Physician_ID==@phys_id').Product_Name_.value_counts(dropna=True).index[0]\n",
    "    else:\n",
    "        return df_scrap.query('Physician_ID==@phys_id').Product_Name_.value_counts(dropna=False).index[0]\n",
    "\n",
    "df_physicians['Max_Prod_Name']=df_physicians['id'].apply(max_prod_occuring)\n",
    "\n",
    "def max_prod_value(phys_id):\n",
    "    return df_scrap.query('Physician_ID==@phys_id').sort_values('Total_Amount_of_Payment_USDollars',ascending=False).Product_Name_.iloc[0]\n",
    "\n",
    "df_physicians['Max_Prod_Name_value']=df_physicians['id'].apply(max_prod_value)\n",
    "\n",
    "df_physicians['Form_of_Payment_or_Transfer_of_Value']=0\n",
    "df_physicians['Nature_of_Payment_or_Transfer_of_Value']=0\n",
    "df_physicians['City_of_Travel']=0\n",
    "df_physicians['State_of_Travel']=0\n",
    "df_physicians['Related_Product_Indicator']=0\n",
    "\n",
    "for i in range(df_physicians.shape[0]):\n",
    "    phys=df_physicians.id.iloc[i]\n",
    "    df_scrap=df_payments.query('Physician_ID==@phys').sort_values('Total_Amount_of_Payment_USDollars')\n",
    "    df_physicians['Form_of_Payment_or_Transfer_of_Value'].iloc[i]=df_scrap.Form_of_Payment_or_Transfer_of_Value.iloc[0]\n",
    "    df_physicians['Nature_of_Payment_or_Transfer_of_Value']=df_scrap.Nature_of_Payment_or_Transfer_of_Value.iloc[0]\n",
    "    df_physicians['City_of_Travel']=df_scrap.City_of_Travel.iloc[0]\n",
    "    df_physicians['State_of_Travel']=df_scrap.State_of_Travel.iloc[0]\n",
    "    df_physicians['Related_Product_Indicator']=df_scrap.Related_Product_Indicator.iloc[0]\n",
    "\n",
    "df_physicians['Form_of_Payment_or_Transfer_of_Value_occ']=0\n",
    "df_physicians['Nature_of_Payment_or_Transfer_of_Value_occ']=0\n",
    "df_physicians['City_of_Travel_occ']=0\n",
    "df_physicians['State_of_Travel_occ']=0\n",
    "df_physicians['Related_Product_Indicator_occ']=0\n",
    "\n",
    "columnsstuff=['Form_of_Payment_or_Transfer_of_Value','Nature_of_Payment_or_Transfer_of_Value','City_of_Travel','State_of_Travel','Related_Product_Indicator']\n",
    "\n",
    "for i in range(df_physicians.shape[0]):\n",
    "    phys=df_physicians.id.iloc[i]\n",
    "    df_scrap=df_payments.query('Physician_ID==@phys')\n",
    "    \n",
    "    for col in columnsstuff:\n",
    "        if(str(df_scrap[col].value_counts(dropna=False).index[0])==\"nan\"):\n",
    "            if(df_scrap[col].value_counts(dropna=False).size<2):\n",
    "                df_physicians[col+\"_occ\"].iloc[i] = df_scrap[col].value_counts(dropna=False).index[0]\n",
    "            else:\n",
    "                df_physicians[col+\"_occ\"].iloc[i] =  df_scrap[col].value_counts(dropna=True).index[0]\n",
    "        else:\n",
    "            df_physicians[col+\"_occ\"].iloc[i] = df_scrap[col].value_counts(dropna=False).index[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_physicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index_col'] = df.index\n",
    "df=pd.wide_to_long(df, stubnames='License_State_', i=['index_col'],j='License_State_Number').reset_index()\n",
    "df.drop(columns=['index_col'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsDrop=['First_Name', 'Middle_Name', 'Last_Name', 'Name_Suffix','Province',\n",
    "            'Country_Phys', 'License_State_Number']\n",
    "columns_encode=['Nature_of_Payment_or_Transfer_of_Value_occ','Form_of_Payment_or_Transfer_of_Value_occ',\n",
    "            'Related_Product_Indicator_occ','Form_of_Payment_or_Transfer_of_Value','City_of_Travel_occ',\n",
    "                'State_of_Travel_occ','License_State_','Max_Prod_Name_value','City', 'State_Phys', 'Zipcode','Primary_Specialty','Max_Prod_Name','Nature_of_Payment_or_Transfer_of_Value', 'City_of_Travel','State_of_Travel', 'Related_Product_Indicator',]\n",
    "\n",
    "\n",
    "\n",
    "df.drop(columns=columnsDrop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['License_State_'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_encode:\n",
    "    df[column]=df[column].astype('category')\n",
    "    df[column]=df[column].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df[df.set==\"train\"]\n",
    "df_test=df[df.set==\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###drop set column\n",
    "df_test.drop(columns=['set'],inplace=True)\n",
    "df_train.drop(columns=['set'],inplace=True)\n",
    "\n",
    "##send predicted attribute to end\n",
    "first_col = df_train.pop(\"Ownership_Interest\")\n",
    "df_train.insert((df_train.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Ownership_Interest\")\n",
    "df_test.insert((df_test.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "##send Physician ID to end\n",
    "first_col = df_train.pop(\"id\")\n",
    "df_train.insert((df_train.shape[1]),\"id\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"id\")\n",
    "df_test.insert((df_test.shape[1]),\"id\",first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "##downsampling\n",
    "df_train_maj=df_train[df_train.Ownership_Interest==0]\n",
    "df_train_min=df_train[df_train.Ownership_Interest==1]\n",
    "df_train_maj_down=resample(df_train_maj, replace=False, n_samples=df_train_min.shape[0], random_state=2021)\n",
    "df_train_final = pd.concat([df_train_maj_down, df_train_min])\n",
    "\n",
    "#upsample\n",
    "# df_train_maj=df_train[df_train.Ownership_Interest==0]\n",
    "# df_train_min=df_train[df_train.Ownership_Interest==1]\n",
    "# df_train_min_up=resample(df_train_min, replace=True, n_samples=1066, random_state=2021)\n",
    "# df_train_final = pd.concat([df_train_min_up, df_train_maj])\n",
    "\n",
    "###test train split of own train set\n",
    "df_train_final['is_train']=np.random.uniform(0,1,len(df_train_final)) <=.80\n",
    "train, test = df_train_final[df_train_final['is_train']==True], df_train_final[df_train_final['is_train']==False]\n",
    "train = shuffle(train,random_state=2021)\n",
    "test = shuffle(test,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###feature and label split\n",
    "features=train[train.columns[0:(train.shape[1]-3)]]\n",
    "y=train['Ownership_Interest']\n",
    "x_test = test[test.columns[0:(test.shape[1]-3)]]\n",
    "y_test = test['Ownership_Interest']\n",
    "\n",
    "###model training\n",
    "clf = RandomForestClassifier( max_features='sqrt',    min_samples_leaf= 2, min_samples_split= 9, n_estimators= 1018, n_jobs= -1, oob_score= True, random_state= 2021)\n",
    "\n",
    "clf.fit(features, y)\n",
    "\n",
    "# Accuracy Scores\n",
    "print ('Internal Accuracy Score', clf.oob_score_)\n",
    "print ('RF accuracy: TRAINING', clf.score(features,y))\n",
    "print ('RF accuracy: TESTING', clf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_id_list=df_test['id']\n",
    "predict_set=df_test\n",
    "predict_set.drop(columns=['id','Ownership_Interest'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict(predict_set)\n",
    "submit={'Physician_ID':phys_id_list, 'Score':score}\n",
    "submit_df=pd.DataFrame(data=submit)\n",
    "\n",
    "scoreProb=clf.predict_proba(predict_set)\n",
    "scoreProb_df=pd.DataFrame(data=scoreProb)\n",
    "scoreProb_df.columns=['Prob_0','Prob_1']\n",
    "\n",
    "submit_df['Prob_0']=0\n",
    "submit_df['Prob_1']=0\n",
    "for i in range(submit_df.shape[0]):\n",
    "    submit_df['Prob_0'].iloc[i]=scoreProb_df['Prob_0'].iloc[i]\n",
    "    submit_df['Prob_1'].iloc[i]=scoreProb_df['Prob_1'].iloc[i]\n",
    "    \n",
    "    \n",
    "physIDLIST=submit_df.Physician_ID.unique()\n",
    "scrapScore=[None]*1000\n",
    "for i in range(physIDLIST.size):\n",
    "    phys=physIDLIST[i]\n",
    "    df_scrap=submit_df.query('Physician_ID==@phys')\n",
    "    if(df_scrap.Score.nunique()>1):\n",
    "        if(df_scrap.Prob_0.sum()>df_scrap.Prob_1.sum()):\n",
    "            scrapScore[i]=0\n",
    "        else:\n",
    "            scrapScore[i]=1\n",
    "    else:\n",
    "        scrapScore[i]=df_scrap.Score.iloc[0]\n",
    "\n",
    "finalDict={'id':physIDLIST, 'prediction':scrapScore}\n",
    "finalSub=pd.DataFrame(data=finalDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalSub.to_csv(\"./submission9test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
