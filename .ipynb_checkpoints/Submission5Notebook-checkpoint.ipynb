{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import seaborn as sns\n",
    "import random as r\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "# For downsampling\n",
    "from sklearn.utils import resample,shuffle\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"./companies.csv\")\n",
    "df_payments = pd.read_csv(\"./payments.csv\")\n",
    "df_physicians = pd.read_csv(\"./physicians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.rename({\"State\":\"State_Comp\",\"Country\":\"Country_Comp\"}, axis='columns', inplace=True)\n",
    "df_physicians.rename({\"State\":\"State_Phys\",\"Country\":\"Country_Phys\"}, axis='columns', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.merge(df_payments, df_physicians, left_on='Physician_ID', right_on='id', how='left').drop('id', axis=1)\n",
    "df = pd.merge(df, df_companies, on='Company_ID', how='left')\n",
    "df.rename({\"Name\":\"Company_Name\"}, axis='columns', inplace=True)\n",
    "\n",
    "###test safekeeping dataframe\n",
    "df_main_test=df[df.set==\"test\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower case all strings\n",
    "df = df.astype(str)\n",
    "for column in df.columns:\n",
    "     if(df[column].dtype=='object'):\n",
    "        df[column] = df[column].str.lower()\n",
    "\n",
    "# Data Squeezing\n",
    "df_squeezed=df\n",
    "df_squeezed['index_col'] = df.index\n",
    "df_squeezed=pd.wide_to_long(df_squeezed, stubnames='Product_Name_', i=['index_col'],j='Product_Name_Number').reset_index()\n",
    "df_squeezed.drop(columns=['index_col'],inplace=True)\n",
    "\n",
    "dfNew=df_squeezed.query('Product_Name_Number==\"1\"')\n",
    "dfNew['Product_Type']=dfNew['Product_Type_1']\n",
    "dfNew2=df_squeezed.query('Product_Name_Number==\"2\"')\n",
    "dfNew2['Product_Type']=dfNew2['Product_Type_2']\n",
    "dfNew3=df_squeezed.query('Product_Name_Number==\"3\"')\n",
    "dfNew3['Product_Type']=dfNew3['Product_Type_3']\n",
    "dfNew=pd.concat([dfNew, dfNew2])\n",
    "dfNew=pd.concat([dfNew, dfNew3])\n",
    "\n",
    "string=\"Code\"\n",
    "dfNew1=dfNew.query('Product_Name_Number==\"1\"')\n",
    "dfNew1['Product_'+string]=dfNew1['Product_'+string+'_1']\n",
    "dfNew2=dfNew.query('Product_Name_Number==\"2\"')\n",
    "dfNew2['Product_'+string]=dfNew2['Product_'+string+'_2']\n",
    "dfNew3=dfNew.query('Product_Name_Number==\"3\"')\n",
    "dfNew3['Product_'+string]=dfNew3['Product_'+string+'_3']\n",
    "dfNew1=pd.concat([dfNew1, dfNew2])\n",
    "dfNew1=pd.concat([dfNew1, dfNew3])\n",
    "dfNew=dfNew1\n",
    "dfNew\n",
    "\n",
    "string=\"Category\"\n",
    "dfNew1=dfNew.query('Product_Name_Number==\"1\"')\n",
    "dfNew1['Product_'+string]=dfNew1['Product_'+string+'_1']\n",
    "dfNew2=dfNew.query('Product_Name_Number==\"2\"')\n",
    "dfNew2['Product_'+string]=dfNew2['Product_'+string+'_2']\n",
    "dfNew3=dfNew.query('Product_Name_Number==\"3\"')\n",
    "dfNew3['Product_'+string]=dfNew3['Product_'+string+'_3']\n",
    "dfNew1=pd.concat([dfNew1, dfNew2])\n",
    "dfNew1=pd.concat([dfNew1, dfNew3])\n",
    "dfNew=dfNew1\n",
    "\n",
    "dfNew['index_col'] = dfNew.index\n",
    "dfNew=pd.wide_to_long(dfNew, stubnames='License_State_', i=['index_col'],j='License_State_Number').reset_index()\n",
    "dfNew.drop(columns=['index_col'],inplace=True)\n",
    "\n",
    "#Dropping Columns\n",
    "dfNew.drop(columns=['Product_Name_Number','License_State_Number','First_Name', 'Middle_Name', 'Last_Name', 'Name_Suffix', \n",
    "                 'Company_Name','Province','Product_Category_1','Product_Category_2','Product_Category_3',\n",
    "                 'Product_Type_1','Product_Type_2','Product_Type_3',\n",
    "                'Product_Code_1','Product_Code_2','Product_Code_3'],inplace=True)\n",
    "\n",
    "dfNewNONE=dfNew.where(dfNew!=\"nan\",None)\n",
    "dfScrap=dfNewNONE.dropna(subset=['Product_Name_'])\n",
    "dfScrap=dfScrap.dropna(subset=['Product_Type'])\n",
    "df=dfScrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING CELL\n",
    "df = df.astype(str)\n",
    "for column in df.columns:\n",
    "     if(df[column].dtype=='object'):\n",
    "        df[column] = df[column].str.lower()\n",
    "\n",
    "#Convert to Date\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "#type conv after str conv\n",
    "df[['Company_ID','Number_of_Payments']]=df[['Company_ID','Number_of_Payments']].astype(int)\n",
    "df['Total_Amount_of_Payment_USDollars']=df['Total_Amount_of_Payment_USDollars'].astype(float)\n",
    "\n",
    "\n",
    "columns_encode=['Product_Code','Product_Name_','License_State_','Product_Type','Product_Category','Nature_of_Payment_or_Transfer_of_Value','Form_of_Payment_or_Transfer_of_Value','Zipcode','Third_Party_Recipient', 'Charity', 'Third_Party_Covered','Contextual_Information', 'Related_Product_Indicator','Primary_Specialty']\n",
    "for column in columns_encode:\n",
    "    df[column]=df[column].astype('category')\n",
    "    df[column]=df[column].cat.codes\n",
    "    \n",
    "name_list = pd.unique(df[['Country_Comp', 'Country_Phys','Country_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Country_Comp'] = df['Country_Comp'].apply(product_encode)\n",
    "df['Country_Phys'] = df['Country_Phys'].apply(product_encode)\n",
    "df['Country_of_Travel'] = df['Country_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['State_Comp', 'State_Phys', 'State_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['State_Comp'] = df['State_Comp'].apply(product_encode)\n",
    "df['State_Phys'] = df['State_Phys'].apply(product_encode)\n",
    "df['State_of_Travel'] = df['State_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['City_of_Travel', 'City']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['City_of_Travel'] = df['City_of_Travel'].apply(product_encode)\n",
    "df['City'] = df['City'].apply(product_encode)\n",
    "\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"yes\"),1,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"no\"),0,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=df['Ownership_Indicator'].astype(int)\n",
    "\n",
    "df['Date_year']=df['Date'].dt.year\n",
    "df['Date_month']=df['Date'].dt.month\n",
    "df['Date_day']=df['Date'].dt.day\n",
    "df.drop(columns=['Date'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###SPLIT\n",
    "df_test=df[df.set==\"test\"]\n",
    "df_train=df[df.set==\"train\"]\n",
    "\n",
    "###drop set column\n",
    "df_test.drop(columns=['set'],inplace=True)\n",
    "df_train.drop(columns=['set'],inplace=True)\n",
    "\n",
    "##send predicted attribute to end\n",
    "first_col = df_train.pop(\"Ownership_Indicator\")\n",
    "df_train.insert((df_train.shape[1]),\"Ownership_Indicator\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Ownership_Indicator\")\n",
    "df_test.insert((df_test.shape[1]),\"Ownership_Indicator\",first_col)\n",
    "\n",
    "##send Physician ID to end\n",
    "first_col = df_train.pop(\"Physician_ID\")\n",
    "df_train.insert((df_train.shape[1]),\"Physician_ID\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Physician_ID\")\n",
    "df_test.insert((df_test.shape[1]),\"Physician_ID\",first_col)\n",
    "\n",
    "##send Record ID to end\n",
    "first_col = df_train.pop(\"Record_ID\")\n",
    "df_train.insert((df_train.shape[1]),\"Record_ID\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Record_ID\")\n",
    "df_test.insert((df_test.shape[1]),\"Record_ID\",first_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2021)\n",
    "###downsampling\n",
    "df_train_maj=df_train[df_train.Ownership_Indicator==0]\n",
    "df_train_min=df_train[df_train.Ownership_Indicator==1]\n",
    "df_train_maj_down=resample(df_train_maj, replace=False, n_samples=df_train_min.shape[0], random_state=2021)\n",
    "df_train_final = pd.concat([df_train_maj_down, df_train_min])\n",
    "\n",
    "###test train split of own train set\n",
    "df_train_final['is_train']=np.random.uniform(0,1,len(df_train_final)) <=.80\n",
    "train, test = df_train_final[df_train_final['is_train']==True], df_train_final[df_train_final['is_train']==False]\n",
    "train = shuffle(train,random_state=2021)\n",
    "test = shuffle(test,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###feature and label split\n",
    "features=train[train.columns[0:(train.shape[1]-4)]]\n",
    "y=train['Ownership_Indicator']\n",
    "x_test = test[test.columns[0:(test.shape[1]-4)]]\n",
    "y_test = test['Ownership_Indicator']\n",
    "\n",
    "###model training\n",
    "clf = RandomForestClassifier(n_jobs=-1, oob_score = True, n_estimators = 196, random_state=2021)\n",
    "clf.fit(features, y)\n",
    "test_acc=clf.score(x_test,y_test)\n",
    "\n",
    "    # Accuracy Scores\n",
    "print ('Internal Accuracy Score', clf.oob_score_)\n",
    "print ('RF accuracy: TRAINING', clf.score(features,y))\n",
    "print ('RF accuracy: TESTING', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_id_list=df_test['Physician_ID']\n",
    "predict_set=df_test\n",
    "predict_set.drop(columns=['Physician_ID','Ownership_Indicator','Record_ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict(predict_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit={'Physician_ID':phys_id_list, 'Score':score}\n",
    "submit_df=pd.DataFrame(data=submit)\n",
    "physUnique=submit_df['Physician_ID'].unique()\n",
    "\n",
    "sc=[None]*1000\n",
    "for i in range(physUnique.size):\n",
    "    physician=physUnique[i]\n",
    "    if(submit_df.query('Physician_ID==@physician and Score==1').shape[0]>0):\n",
    "        sc[i]=1\n",
    "    else:\n",
    "        sc[i]=0\n",
    "\n",
    "final_submit={'id':physUnique, 'prediction':sc}\n",
    "fs_df=pd.DataFrame(data=final_submit)\n",
    "fs_df.to_csv(\"./submission5.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
