{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "import seaborn as sns\n",
    "import random as r\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import preprocessing\n",
    "# For downsampling\n",
    "from sklearn.utils import resample,shuffle\n",
    "np.random.seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies = pd.read_csv(\"./companies.csv\")\n",
    "df_payments = pd.read_csv(\"./payments.csv\")\n",
    "df_physicians = pd.read_csv(\"./physicians.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phys_OI(phys_id):\n",
    "    if(df_payments.query('Physician_ID==@phys_id and Ownership_Indicator==\"Yes\"').shape[0]>0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df_physicians['Ownership_Interest']=df_physicians['id'].apply(phys_OI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_companies.rename({\"State\":\"State_Comp\",\"Country\":\"Country_Comp\"}, axis='columns', inplace=True)\n",
    "df_physicians.rename({\"State\":\"State_Phys\",\"Country\":\"Country_Phys\"}, axis='columns', inplace=True)\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.merge(df_payments, df_physicians, left_on='Physician_ID', right_on='id', how='left').drop('id', axis=1)\n",
    "df = pd.merge(df, df_companies, on='Company_ID', how='left')\n",
    "df.rename({\"Name\":\"Company_Name\"}, axis='columns', inplace=True)\n",
    "\n",
    "\n",
    "###test safekeeping dataframe\n",
    "df_main_test=df[df.set==\"test\"]\n",
    "\n",
    "df = df.astype(str)\n",
    "for column in df.columns:\n",
    "     if(df[column].dtype=='object'):\n",
    "        df[column] = df[column].str.lower()\n",
    "\n",
    "#Convert to Date\n",
    "df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "#type conv after str conv\n",
    "df[['Company_ID','Number_of_Payments','Ownership_Interest']]=df[['Company_ID','Number_of_Payments','Ownership_Interest']].astype(int)\n",
    "df['Total_Amount_of_Payment_USDollars']=df['Total_Amount_of_Payment_USDollars'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DROPPING RECORDS\n",
    "df_scrap=df.query('Product_Code_1!=\"nan\" and Product_Name_1==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n",
    "\n",
    "df_scrap=df.query('Product_Code_2!=\"nan\" and Product_Name_2==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n",
    "\n",
    "df_scrap=df.query('Product_Code_3!=\"nan\" and Product_Name_3==\"nan\" and set!=\"test\"', engine='python')\n",
    "df_scrap.Ownership_Indicator.value_counts()\n",
    "df=pd.concat([df, df_scrap]).drop_duplicates(keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###ENCODING CELL\n",
    "\n",
    "name_list = pd.unique(df[['Product_Name_1', 'Product_Name_2', 'Product_Name_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Name_1'] = df['Product_Name_1'].apply(product_encode)\n",
    "df['Product_Name_2'] = df['Product_Name_2'].apply(product_encode)\n",
    "df['Product_Name_3'] = df['Product_Name_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Code_1', 'Product_Code_2', 'Product_Code_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Code_1'] = df['Product_Code_1'].apply(product_encode)\n",
    "df['Product_Code_2'] = df['Product_Code_2'].apply(product_encode)\n",
    "df['Product_Code_3'] = df['Product_Code_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Category_1', 'Product_Category_2', 'Product_Category_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Category_1'] = df['Product_Category_1'].apply(product_encode)\n",
    "df['Product_Category_2'] = df['Product_Category_2'].apply(product_encode)\n",
    "df['Product_Category_3'] = df['Product_Category_3'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Product_Type_1', 'Product_Type_2','Product_Type_3']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Product_Type_1'] = df['Product_Type_1'].apply(product_encode)\n",
    "df['Product_Type_2'] = df['Product_Type_2'].apply(product_encode)\n",
    "df['Product_Type_3'] = df['Product_Type_3'].apply(product_encode)\n",
    "\n",
    "\n",
    "name_list = pd.unique(df[['License_State_1', 'License_State_2', 'License_State_3', 'License_State_4', 'License_State_5']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def license_encode(license_state):\n",
    "    return name_list_dict.get(license_state)\n",
    "\n",
    "df['License_State_1']=df['License_State_1'].apply(license_encode)\n",
    "df['License_State_2']=df['License_State_2'].apply(license_encode)\n",
    "df['License_State_3']=df['License_State_3'].apply(license_encode)\n",
    "df['License_State_4']=df['License_State_4'].apply(license_encode)\n",
    "df['License_State_5']=df['License_State_5'].apply(license_encode)\n",
    "\n",
    "name_list = pd.unique(df[['Country_Comp', 'Country_Phys','Country_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['Country_Comp'] = df['Country_Comp'].apply(product_encode)\n",
    "df['Country_Phys'] = df['Country_Phys'].apply(product_encode)\n",
    "df['Country_of_Travel'] = df['Country_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['State_Comp', 'State_Phys', 'State_of_Travel']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['State_Comp'] = df['State_Comp'].apply(product_encode)\n",
    "df['State_Phys'] = df['State_Phys'].apply(product_encode)\n",
    "df['State_of_Travel'] = df['State_of_Travel'].apply(product_encode)\n",
    "\n",
    "name_list = pd.unique(df[['City_of_Travel', 'City']].values.ravel('K'))\n",
    "# name_list = np.delete(name_list,np.where(name_list==\"nan\"))\n",
    "name_list_dict = {}\n",
    "int_code=int(1)\n",
    "for name in name_list:\n",
    "    name_list_dict.update({name:int_code})\n",
    "    int_code+=1\n",
    "\n",
    "def product_encode(product_name):\n",
    "    return name_list_dict.get(product_name)\n",
    "\n",
    "df['City_of_Travel'] = df['City_of_Travel'].apply(product_encode)\n",
    "df['City'] = df['City'].apply(product_encode)\n",
    "\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"yes\"),1,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=np.where((df.Ownership_Indicator == \"no\"),0,df.Ownership_Indicator)\n",
    "df['Ownership_Indicator']=df['Ownership_Indicator'].astype(int)\n",
    "\n",
    "df['Date_year']=df['Date'].dt.year\n",
    "df['Date_month']=df['Date'].dt.month\n",
    "df['Date_day']=df['Date'].dt.day\n",
    "\n",
    "columns_encode=['Nature_of_Payment_or_Transfer_of_Value','Form_of_Payment_or_Transfer_of_Value','Zipcode','Third_Party_Recipient', 'Charity', 'Third_Party_Covered','Contextual_Information', 'Related_Product_Indicator','Primary_Specialty']\n",
    "for column in columns_encode:\n",
    "    df[column]=df[column].astype('category')\n",
    "    df[column]=df[column].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###DROPPING COLUMNS\n",
    "df.drop(columns=['Ownership_Indicator','Date','Record_ID', 'First_Name', 'Middle_Name', 'Last_Name', 'Name_Suffix', 'Company_Name','Province'],inplace=True)\n",
    "\n",
    "###SPLIT\n",
    "df_test=df[df.set==\"test\"]\n",
    "df_train=df[df.set==\"train\"]\n",
    "\n",
    "###drop set column\n",
    "df_test.drop(columns=['set'],inplace=True)\n",
    "df_train.drop(columns=['set'],inplace=True)\n",
    "\n",
    "##send predicted attribute to end\n",
    "first_col = df_train.pop(\"Ownership_Interest\")\n",
    "df_train.insert((df_train.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Ownership_Interest\")\n",
    "df_test.insert((df_test.shape[1]),\"Ownership_Interest\",first_col)\n",
    "\n",
    "##send Physician ID to end\n",
    "first_col = df_train.pop(\"Physician_ID\")\n",
    "df_train.insert((df_train.shape[1]),\"Physician_ID\",first_col)\n",
    "\n",
    "first_col = df_test.pop(\"Physician_ID\")\n",
    "df_test.insert((df_test.shape[1]),\"Physician_ID\",first_col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###downsampling\n",
    "df_train_maj=df_train[df_train.Ownership_Interest==0]\n",
    "df_train_min=df_train[df_train.Ownership_Interest==1]\n",
    "df_train_maj_down=resample(df_train_maj, replace=False, n_samples=df_train_min.shape[0], random_state=2021)\n",
    "df_train_final = pd.concat([df_train_maj_down, df_train_min])\n",
    "\n",
    "###test train split of own train set\n",
    "df_train_final['is_train']=np.random.uniform(0,1,len(df_train_final)) <=.80\n",
    "train, test = df_train_final[df_train_final['is_train']==True], df_train_final[df_train_final['is_train']==False]\n",
    "train = shuffle(train,random_state=2021)\n",
    "test = shuffle(test,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###feature and label split\n",
    "features=train[train.columns[0:(train.shape[1]-3)]]\n",
    "y=train['Ownership_Interest']\n",
    "x_test = test[test.columns[0:(test.shape[1]-3)]]\n",
    "y_test = test['Ownership_Interest']\n",
    "\n",
    "###model training\n",
    "clf = RandomForestClassifier(n_jobs=-1, oob_score = True, n_estimators = 89, random_state=2021)\n",
    "clf.fit(features, y)\n",
    "test_acc=clf.score(x_test,y_test)\n",
    "\n",
    "    # Accuracy Scores\n",
    "print ('Internal Accuracy Score', clf.oob_score_)\n",
    "print ('RF accuracy: TRAINING', clf.score(features,y))\n",
    "print ('RF accuracy: TESTING', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phys_id_list=df_main_test['Physician_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_set=df_test\n",
    "predict_set.drop(columns=['Physician_ID','Ownership_Interest'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict(predict_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit={'Physician_ID':phys_id_list, 'Score':score}\n",
    "submit_df=pd.DataFrame(data=submit)\n",
    "physUnique=submit_df['Physician_ID'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sc=[None]*1000\n",
    "for i in range(physUnique.size):\n",
    "    physician=physUnique[i]\n",
    "    if (submit_df.query('Physician_ID==@physician and Score==1').shape[0]<submit_df.query('Physician_ID==@physician and Score==0').shape[0]):\n",
    "        sc[i]=0\n",
    "    else:\n",
    "        sc[i]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit={'id':physUnique, 'prediction':sc}\n",
    "fs_df=pd.DataFrame(data=final_submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_df.to_csv(\"./submission4.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
